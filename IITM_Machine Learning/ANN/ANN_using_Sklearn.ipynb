{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6k4L7MrSXzTQ"
   },
   "outputs": [],
   "source": [
    "## Business case:-On the basis of given parameters(features) our\n",
    "#target is to find\n",
    "## whether a patient will have B type or M type cancer.\n",
    "## So we are solving a classifcation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lYLGprfsMa9"
   },
   "outputs": [],
   "source": [
    "## importing the libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feOcpKz0XzTW",
    "outputId": "4c12376c-c1f4-47e6-a0ac-7453b00a6114"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('breast_cancer.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qZpAZnQXzTY"
   },
   "outputs": [],
   "source": [
    "## basic checks\n",
    "## head,tail,describe,info,missing value(is null),check if any categorical data\n",
    "## unique,value_counts.\n",
    "## Plotting and getting insights from data(univariate analysis,bivariate\n",
    "## and multivariate analysis)(matplotlib and seaborn)\n",
    "## Feature selection:-Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uV7LFmefXzTa"
   },
   "outputs": [],
   "source": [
    "## creating independent and dependent variables\n",
    "X = data.iloc[:,2:-1]\n",
    "y = data.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oh0AnG6hXzTb",
    "outputId": "68f8ee93-4c46-4717-a035-1d9ab182a373"
   },
   "outputs": [],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuS074MGsMbU"
   },
   "outputs": [],
   "source": [
    "## Scaling the data as the magnitude of variables are varying lot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler() ## object creation\n",
    "sclaed_x=sc.fit_transform(X) ## transforming the data\n",
    "X = pd.DataFrame(sclaed_x,columns=X.columns) ##converting the arrays\n",
    "## to dataframe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XTwZJ84XzTd"
   },
   "outputs": [],
   "source": [
    "##creating training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,\n",
    "                                test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NpM1nimXzTe"
   },
   "outputs": [],
   "source": [
    "## check train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhwV2hOUsMbX"
   },
   "outputs": [],
   "source": [
    "## model creation\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier( hidden_layer_sizes=(50,3), # 50 neurons, 3 hidden layers\n",
    "                       learning_rate_init=0.1,\n",
    "                       max_iter=100,\n",
    "                       random_state=2) ## model object creation max_iter=Stopping parameter\n",
    "model.fit(X_train,y_train) ## training the data\n",
    "y_predict_proba = model.predict_proba(X_test) ## predicting the pro\n",
    "## bability of class\n",
    "y_predict = model.predict(X_test)\n",
    "y_train_predict = model.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RYCqYN1PsMbZ",
    "outputId": "e3dd7b29-75f8-45d1-b5f9-93f90cfd950a"
   },
   "outputs": [],
   "source": [
    "## Evaluating the model created\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "print(\"Train accuracy :\",accuracy_score(y_train,y_train_predict))\n",
    "print(\"Test accuracy :\",accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Kjw5qLqsMba",
    "outputId": "e4bc2e35-7d0e-438a-f54b-033a9bc1ff73"
   },
   "outputs": [],
   "source": [
    "## getting the confusion matrix\n",
    "pd.crosstab(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "We_aBfCFsMbc",
    "outputId": "88a934c3-2919-4249-f180-62f700e3e9e5"
   },
   "outputs": [],
   "source": [
    "## getting classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EG2d3LU_X10n"
   },
   "source": [
    "Pros:-\n",
    "1) Neural networks are flexible and can be used for both regression and classification problems. Any data which can be made numeric can be used in the model, as neural network is a mathematical model with approximation functions.\n",
    "\n",
    "2)Neural networks are good to model with nonlinear data with large number of inputs; for example, images. It is reliable in an approach of tasks involving many features. It works by splitting the problem of classification into a layered network of simpler elements.\n",
    "\n",
    "3)Once trained, the predictions are pretty fast.\n",
    "4)Neural networks can be trained with any number of inputs and layers.\n",
    "5)Neural networks work best with more data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RYYCJ6LYKnD"
   },
   "source": [
    "Cons:-\n",
    "1)Neural networks are black boxes, meaning we cannot know how much each independent variable is influencing the dependent variables.\n",
    "2)It is computationally very expensive and time consuming to train with traditional CPUs.\n",
    "3)Neural networks depend a lot on training data. This leads to the problem of over-fitting and generalization. The mode relies more on the training data and may be tuned to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAKcc2C8sMbd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_qwT9n4sMbe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qb37A0KhsMbf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJ7my9lysMbg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoFi0YrlsMbh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ANN_using_Sklearn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
