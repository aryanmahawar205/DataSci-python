{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Series\n",
    "\n",
    "Series in Pandas is just like a NumPy array. The only difference that lies here is that Series can have axis labels. Some data / object having an axis label means to say that it can be indexed by a label (which could essentially be anything you want) instead of the traditional 0 number indexing in Python. A series can also hold any arbitrary Python object or a collection of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas Series using List (Traditional Index) - \n",
      " 0    10\n",
      "1    20\n",
      "2    30\n",
      "dtype: int64\n",
      "\n",
      "Pandas Series using List (Custom Index) - \n",
      " a    10\n",
      "b    20\n",
      "c    30\n",
      "dtype: int64\n",
      "\n",
      "Pandas Series using NumPy Array (Traditional Index) - \n",
      " 0    10\n",
      "1    20\n",
      "2    30\n",
      "dtype: int32\n",
      "\n",
      "Pandas Series using NumPy Array (Custom Index) - \n",
      " a    10\n",
      "b    20\n",
      "c    30\n",
      "dtype: int32\n",
      "\n",
      "Pandas Series using Dictionary - \n",
      " a    10\n",
      "b    20\n",
      "c    30\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# we could essentially convert a list, numpy array or a dictionary into a Pandas series\n",
    "\n",
    "keys = ['a', 'b', 'c'] # a regular Python list\n",
    "ls = [10, 20, 30] # a regular Python list\n",
    "arr = np.array(ls) # a numpy array\n",
    "d = {'a':10, 'b':20, 'c':30} # a Python dictionary\n",
    "\n",
    "# creating Pandas series using a list\n",
    "seriesListRegularIndexing = pd.Series(data=ls) # Series created will have traditional 0 based indexing\n",
    "print(\"Pandas Series using List (Traditional Index) - \\n\", seriesListRegularIndexing)\n",
    "seriesListCustomIndexing = pd.Series(data=ls, index=keys) # Series created will have indexing as specified in list Keys\n",
    "print(\"\\nPandas Series using List (Custom Index) - \\n\", seriesListCustomIndexing)\n",
    "\n",
    "# creating Pandas series using a NumPy array\n",
    "seriesArrayRegularIndexing = pd.Series(data=arr) # Series created will have traditional 0 based indexing\n",
    "print(\"\\nPandas Series using NumPy Array (Traditional Index) - \\n\", seriesArrayRegularIndexing)\n",
    "seriesArrayCustomIndexing = pd.Series(data=arr, index=keys) # Series created will have indexing as specified in list Keys\n",
    "print(\"\\nPandas Series using NumPy Array (Custom Index) - \\n\", seriesArrayCustomIndexing)\n",
    "\n",
    "# creating Pandas series using a Python Dictionary\n",
    "# by default in creation of Series using a Dictionary, the keys are mapped to the index and values as the the actual elements of the series\n",
    "seriesDict = pd.Series(data=d) # Series created will have traditional 0 based indexing\n",
    "print(\"\\nPandas Series using Dictionary - \\n\", seriesDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - DataFrames\n",
    "\n",
    "A Pandas DataFrame is just another bunch of series objects, put together to share a same index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic DataFrame - \n",
      "\n",
      "           W         X         Y         Z\n",
      "A  2.706850  0.628133  0.907969  0.503826\n",
      "B  0.651118 -0.319318 -0.848077  0.605965\n",
      "C -2.018168  0.740122  0.528813 -0.589001\n",
      "D  0.188695 -0.758872 -0.933237  0.955057\n",
      "E  0.190794  1.978757  2.605967  0.683509\n",
      "\n",
      "\n",
      "Selecting single column (W) - \n",
      "\n",
      " A    2.706850\n",
      "B    0.651118\n",
      "C   -2.018168\n",
      "D    0.188695\n",
      "E    0.190794\n",
      "Name: W, dtype: float64\n",
      "\n",
      "\n",
      "Selecting two columns (W and Z) - \n",
      "\n",
      "           W         Z\n",
      "A  2.706850  0.503826\n",
      "B  0.651118  0.605965\n",
      "C -2.018168 -0.589001\n",
      "D  0.188695  0.955057\n",
      "E  0.190794  0.683509\n",
      "\n",
      "\n",
      "After adding new column - \n",
      "\n",
      "           W         X         Y         Z  newColumn (adding W and Z)\n",
      "A  2.706850  0.628133  0.907969  0.503826                    3.210676\n",
      "B  0.651118 -0.319318 -0.848077  0.605965                    1.257083\n",
      "C -2.018168  0.740122  0.528813 -0.589001                   -2.607169\n",
      "D  0.188695 -0.758872 -0.933237  0.955057                    1.143752\n",
      "E  0.190794  1.978757  2.605967  0.683509                    0.874303\n",
      "\n",
      "\n",
      "Column not deleted in original DataFrame - \n",
      "\n",
      "           W         X         Y         Z  newColumn (adding W and Z)\n",
      "A  2.706850  0.628133  0.907969  0.503826                    3.210676\n",
      "B  0.651118 -0.319318 -0.848077  0.605965                    1.257083\n",
      "C -2.018168  0.740122  0.528813 -0.589001                   -2.607169\n",
      "D  0.188695 -0.758872 -0.933237  0.955057                    1.143752\n",
      "E  0.190794  1.978757  2.605967  0.683509                    0.874303\n",
      "\n",
      "\n",
      "Column deleted in original DataFrame - \n",
      "\n",
      "           W         X         Y         Z\n",
      "A  2.706850  0.628133  0.907969  0.503826\n",
      "B  0.651118 -0.319318 -0.848077  0.605965\n",
      "C -2.018168  0.740122  0.528813 -0.589001\n",
      "D  0.188695 -0.758872 -0.933237  0.955057\n",
      "E  0.190794  1.978757  2.605967  0.683509\n",
      "\n",
      "\n",
      "Row E has been removed from original DataFrame - \n",
      "\n",
      "           W         X         Y         Z\n",
      "A  2.706850  0.628133  0.907969  0.503826\n",
      "B  0.651118 -0.319318 -0.848077  0.605965\n",
      "C -2.018168  0.740122  0.528813 -0.589001\n",
      "D  0.188695 -0.758872 -0.933237  0.955057\n",
      "\n",
      "\n",
      "Selecting row A using loc - \n",
      "\n",
      " W    2.706850\n",
      "X    0.628133\n",
      "Y    0.907969\n",
      "Z    0.503826\n",
      "Name: A, dtype: float64\n",
      "\n",
      "\n",
      "Selecting row A using iloc - \n",
      "\n",
      " W    2.706850\n",
      "X    0.628133\n",
      "Y    0.907969\n",
      "Z    0.503826\n",
      "Name: A, dtype: float64\n",
      "\n",
      "\n",
      "Accessing data at row B and column Y -  -0.8480769834036315\n",
      "\n",
      "\n",
      "Accessing data in rows A and B with columns W and Y - \n",
      "\n",
      "           W         Y\n",
      "A  2.706850  0.907969\n",
      "B  0.651118 -0.848077\n",
      "\n",
      "\n",
      "DataFrame where values are greater than 0 - \n",
      "\n",
      "        W      X      Y      Z\n",
      "A   True   True   True   True\n",
      "B   True  False  False   True\n",
      "C  False   True   True  False\n",
      "D   True  False  False   True\n",
      "\n",
      "\n",
      "To the above boolean DataFrame, here we get vales only to the True correspondent and None / NaN at the False ones - \n",
      "\n",
      "           W         X         Y         Z\n",
      "A  2.706850  0.628133  0.907969  0.503826\n",
      "B  0.651118       NaN       NaN  0.605965\n",
      "C       NaN  0.740122  0.528813       NaN\n",
      "D  0.188695       NaN       NaN  0.955057\n",
      "\n",
      "\n",
      "Some Operations of Conditionally selected DataFrame - \n",
      "\n",
      " A    0.907969\n",
      "B   -0.848077\n",
      "D   -0.933237\n",
      "Name: Y, dtype: float64\n",
      "\n",
      "\n",
      "Some Operations of Conditionally selected DataFrame - \n",
      "\n",
      "           Y         X\n",
      "A  0.907969  0.628133\n",
      "B -0.848077 -0.319318\n",
      "D -0.933237 -0.758872\n",
      "\n",
      "\n",
      "Some Operations of Conditionally selected DataFrame - \n",
      "\n",
      " Empty DataFrame\n",
      "Columns: [W, X, Y, Z]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Using reset_index() function - \n",
      "\n",
      "   index         W         X         Y         Z\n",
      "0     A  2.706850  0.628133  0.907969  0.503826\n",
      "1     B  0.651118 -0.319318 -0.848077  0.605965\n",
      "2     C -2.018168  0.740122  0.528813 -0.589001\n",
      "3     D  0.188695 -0.758872 -0.933237  0.955057\n",
      "\n",
      "\n",
      "Using set_index() function - \n",
      "\n",
      "                       W         X         Y         Z\n",
      "Country Codes                                        \n",
      "CA             2.706850  0.628133  0.907969  0.503826\n",
      "NY             0.651118 -0.319318 -0.848077  0.605965\n",
      "WY            -2.018168  0.740122  0.528813 -0.589001\n",
      "CO             0.188695 -0.758872 -0.933237  0.955057\n",
      "\n",
      "\n",
      "Multi-Level DataFrame - \n",
      "\n",
      "              A         B\n",
      "G1 1  0.302665  1.693723\n",
      "   2 -1.706086 -1.159119\n",
      "   3 -0.134841  0.390528\n",
      "G2 1  0.166905  0.184502\n",
      "   2  0.807706  0.072960\n",
      "   3  0.638787  0.329646\n",
      "\n",
      "\n",
      "Index Labels by default -  [None, None]\n",
      "\n",
      "\n",
      "Index Labels after setting -  ['Groups', 'Num']\n",
      "\n",
      "\n",
      "DataFrame - \n",
      "\n",
      "                    A         B\n",
      "Groups Num                    \n",
      "G1     1    0.302665  1.693723\n",
      "       2   -1.706086 -1.159119\n",
      "       3   -0.134841  0.390528\n",
      "G2     1    0.166905  0.184502\n",
      "       2    0.807706  0.072960\n",
      "       3    0.638787  0.329646\n",
      "\n",
      "\n",
      "Accessing Cross Section of DataFrame where index label in Num and we want to access the values corresponding the index=1 - \n",
      "\n",
      "                A         B\n",
      "Groups                    \n",
      "G1      0.302665  1.693723\n",
      "G2      0.166905  0.184502\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import randn\n",
    "np.random.seed(101)\n",
    "\n",
    "df = pd.DataFrame(data=randn(5,4), index=['A','B','C','D','E'], columns=['W','X','Y','Z'])\n",
    "print(\"Basic DataFrame - \\n\\n\", df)\n",
    "\n",
    "# Selection and Indexing of DataFrames\n",
    "\n",
    "# df['W'] # to access the W column, which is actually a series by itself\n",
    "print(\"\\n\\nSelecting single column (W) - \\n\\n\", df['W'])\n",
    "\n",
    "# df[['W','Z']] to access multiple columns, W and Z\n",
    "# basically to access multiple columns, pass their names as a list\n",
    "print(\"\\n\\nSelecting two columns (W and Z) - \\n\\n\", df[['W', 'Z']])\n",
    "\n",
    "# creating / adding columns\n",
    "df['newColumn (adding W and Z)'] = df['W'] + df['Z']\n",
    "print(\"\\n\\nAfter adding new column - \\n\\n\", df)\n",
    "\n",
    "# removing columns and rows\n",
    "# axis=1 has to be specified while removing a column since by default axis=0 is set which points to the index vales and not the column values\n",
    "# unless specified inplace=True, Pandas does not delete the column in the original DataFrame\n",
    "df.drop('newColumn (adding W and Z)', axis=1)\n",
    "print(\"\\n\\nColumn not deleted in original DataFrame - \\n\\n\", df)\n",
    "df.drop('newColumn (adding W and Z)', axis=1, inplace=True)\n",
    "print(\"\\n\\nColumn deleted in original DataFrame - \\n\\n\", df)\n",
    "# in a similar way rows also could be deleted\n",
    "# but for rows, axis=0 since rows technically are on the indices side of the DataFrame\n",
    "df.drop('E', axis=0, inplace=True)\n",
    "print(\"\\n\\nRow E has been removed from original DataFrame - \\n\\n\", df)\n",
    "\n",
    "# selecting rows from a DataFrame has two methods\n",
    "# Method 1 is using the loc function, wherein you pass the name of the row you wish to select\n",
    "# Method 2 is using the iloc function, where you pass the numeric index of the row you wish to select (regular 0 indexing followed)\n",
    "print(\"\\n\\nSelecting row A using loc - \\n\\n\", df.loc['A'])\n",
    "print(\"\\n\\nSelecting row A using iloc - \\n\\n\", df.iloc[0])\n",
    "# one conclusion we come to is that, even rows are Pandas Series objects\n",
    "\n",
    "# a subset of rows and columns could also be accessed using the NumPy comma notation we saw in the NumPy section\n",
    "print(\"\\n\\nAccessing data at row B and column Y - \", df.loc['B', 'Y'])\n",
    "print(\"\\n\\nAccessing data in rows A and B with columns W and Y - \\n\\n\", df.loc[['A', 'B'], ['W', 'Y']])\n",
    "\n",
    "# Conditional Selection\n",
    "print(\"\\n\\nDataFrame where values are greater than 0 - \\n\\n\", df>0)\n",
    "print(\"\\n\\nTo the above boolean DataFrame, here we get vales only to the True correspondent and None / NaN at the False ones - \\n\\n\", df[df>0])\n",
    "# now certain operation could additionally be performed on Conditionally Selected DataFrames\n",
    "print(\"\\n\\nSome Operations of Conditionally selected DataFrame - \\n\\n\", df[df['W']>0]['Y'])\n",
    "print(\"\\n\\nSome Operations of Conditionally selected DataFrame - \\n\\n\", df[df['W']>0][['Y', 'X']])\n",
    "# for multiple conditions, we can use logical (NOT REALLY) operators as well\n",
    "# the operator for and = &\n",
    "# the operator for or = |\n",
    "print(\"\\n\\nSome Operations of Conditionally selected DataFrame - \\n\\n\", df[(df['W']>0) & (df['Y'] > 1)])\n",
    "\n",
    "# more on Indexing\n",
    "# to reset to default index (0 based indexing), use the reset_index() method\n",
    "# the reset_index() method does not do the changes in place and it also makes your previous indexes as a new column with column name 'index'\n",
    "print(\"\\n\\nUsing reset_index() function - \\n\\n\", df.reset_index())\n",
    "# to set the index to something else which you want to specify, use the set_index() method\n",
    "# again index changes by default are not done in place\n",
    "# in order to do this, you will have to add that particular index column to your DataFrame first\n",
    "newIndices = [\"CA\", \"NY\", \"WY\", \"CO\"]\n",
    "df[\"Country Codes\"] = newIndices\n",
    "print(\"\\n\\nUsing set_index() function - \\n\\n\", df.set_index(\"Country Codes\"))\n",
    "\n",
    "# Multi-Index, Index Hierarchy and Multi-Level DataFrames\n",
    "# Index Levels\n",
    "outside = ['G1','G1','G1','G2','G2','G2']\n",
    "inside = [1,2,3,1,2,3]\n",
    "hier_index = list(zip(outside,inside))\n",
    "hier_index = pd.MultiIndex.from_tuples(hier_index)\n",
    "df = pd.DataFrame(data=randn(6,2), index=hier_index, columns=['A', 'B'])\n",
    "print(\"\\n\\nMulti-Level DataFrame - \\n\\n\", df)\n",
    "print(\"\\n\\nIndex Labels by default - \", df.index.names)\n",
    "# setting index labels\n",
    "df.index.names = ['Groups', 'Num']\n",
    "print(\"\\n\\nIndex Labels after setting - \", df.index.names)\n",
    "print(\"\\n\\nDataFrame - \\n\\n\", df)\n",
    "print(\"\\n\\nAccessing Cross Section of DataFrame where index label in Num and we want to access the values corresponding the index=1 - \\n\\n\", df.xs(1,level='Num'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Missing Data\n",
    "\n",
    "Methods to deal with missing data like Null or NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original Dataframe - \n",
      "\n",
      "      A    B  C\n",
      "0  1.0  5.0  1\n",
      "1  2.0  NaN  2\n",
      "2  NaN  NaN  3\n",
      "\n",
      "\n",
      "Dropping rows with null values - \n",
      "\n",
      "      A    B  C\n",
      "0  1.0  5.0  1\n",
      "\n",
      "\n",
      "Dropping columns with null values - \n",
      "\n",
      "    C\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "\n",
      "\n",
      "Dropping rows with a threshold of 2 - \n",
      "\n",
      "      A    B  C\n",
      "0  1.0  5.0  1\n",
      "1  2.0  NaN  2\n",
      "\n",
      "\n",
      "Filling the Null values with a filler - \n",
      "\n",
      "               A             B  C\n",
      "0           1.0           5.0  1\n",
      "1           2.0  Filler Value  2\n",
      "2  Filler Value  Filler Value  3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "d = {'A':[1,2,np.nan], 'B':[5,np.nan,np.nan], 'C':[1,2,3]}\n",
    "df = pd.DataFrame(d)\n",
    "print(\"\\n\\nOriginal Dataframe - \\n\\n\", df)\n",
    "\n",
    "# to drop rows with null values\n",
    "# have to provide inplace=True to make changes permanent\n",
    "print(\"\\n\\nDropping rows with null values - \\n\\n\", df.dropna())\n",
    "\n",
    "# to drop columns with null values\n",
    "# have to provide inplace=True to make changes permanent\n",
    "print(\"\\n\\nDropping columns with null values - \\n\\n\", df.dropna(axis=1))\n",
    "\n",
    "# setting threshold while dropping\n",
    "# have to provide inplace=True to make changes permanent\n",
    "# in dropna(thresh=2) for example will keep those rows who have atleast 2 or more not Null values and drop the rest\n",
    "print(\"\\n\\nDropping rows with a threshold of 2 - \\n\\n\", df.dropna(thresh=2))\n",
    "\n",
    "# filling the Null values with a filler\n",
    "# have to provide inplace=True to make changes permanent\n",
    "print(\"\\n\\nFilling the Null values with a filler - \\n\\n\", df.fillna(value='Filler Value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Grouping (Groupby)\n",
    "\n",
    "Groupby allows you to group together rows based off a column and perform some aggregate function on them just like in MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original Dataframe - \n",
      "\n",
      "   Company   Person  Sales\n",
      "0    GOOG      Sam    200\n",
      "1    GOOG  Charlie    120\n",
      "2    MSFT      Amy    340\n",
      "3    MSFT  Vanessa    124\n",
      "4      FB     Carl    243\n",
      "5      FB    Sarah    350\n",
      "\n",
      "\n",
      "By Company Count - \n",
      "\n",
      "          Person  Sales\n",
      "Company               \n",
      "FB            2      2\n",
      "GOOG          2      2\n",
      "MSFT          2      2\n",
      "\n",
      "\n",
      "By Company Sum - \n",
      "\n",
      "              Person  Sales\n",
      "Company                   \n",
      "FB        CarlSarah    593\n",
      "GOOG     SamCharlie    320\n",
      "MSFT     AmyVanessa    464\n",
      "\n",
      "\n",
      "Describe Method - \n",
      "\n",
      "         Sales                                                        \n",
      "        count   mean         std    min     25%    50%     75%    max\n",
      "Company                                                              \n",
      "FB        2.0  296.5   75.660426  243.0  269.75  296.5  323.25  350.0\n",
      "GOOG      2.0  160.0   56.568542  120.0  140.00  160.0  180.00  200.0\n",
      "MSFT      2.0  232.0  152.735065  124.0  178.00  232.0  286.00  340.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Company':['GOOG','GOOG','MSFT','MSFT','FB','FB'], 'Person':['Sam','Charlie','Amy','Vanessa','Carl','Sarah'], 'Sales':[200,120,340,124,243,350]}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"\\n\\nOriginal Dataframe - \\n\\n\", df)\n",
    "\n",
    "# now we can use the .groupby() method to group rows together based off a column name\n",
    "# say we group based off the column Company\n",
    "# this actually created a DataFrameGroupBy object which can be referenced to a normal variable and used as a new Dataframe\n",
    "byComp = df.groupby('Company')\n",
    "\n",
    "# now we can call certain aggregate methods off by_comp Dataframe\n",
    "print(\"\\n\\nBy Company Count - \\n\\n\", byComp.count())\n",
    "print(\"\\n\\nBy Company Sum - \\n\\n\", byComp.sum())\n",
    "\n",
    "# a bunch of useful information is provided for the specific column using the .describe() method\n",
    "print(\"\\n\\nDescribe Method - \\n\\n\", byComp.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Merging, Joining and Concatenating\n",
    "\n",
    "There are three main ways of combining Dataframes together in Pandas - Merging, Joining and Concatenating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dataframe1 - \n",
      "\n",
      "     A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3\n",
      "\n",
      "\n",
      "Dataframe2 - \n",
      "\n",
      "     A   B   C   D\n",
      "4  A4  B4  C4  D4\n",
      "5  A5  B5  C5  D5\n",
      "6  A6  B6  C6  D6\n",
      "7  A7  B7  C7  D7\n",
      "\n",
      "\n",
      "Dataframe3 - \n",
      "\n",
      "       A    B    C    D\n",
      "8    A8   B8   C8   D8\n",
      "9    A9   B9   C9   D9\n",
      "10  A10  B10  C10  D10\n",
      "11  A11  B11  C11  D11\n",
      "\n",
      "\n",
      "Concatenating on rows - \n",
      "\n",
      "       A    B    C    D\n",
      "0    A0   B0   C0   D0\n",
      "1    A1   B1   C1   D1\n",
      "2    A2   B2   C2   D2\n",
      "3    A3   B3   C3   D3\n",
      "4    A4   B4   C4   D4\n",
      "5    A5   B5   C5   D5\n",
      "6    A6   B6   C6   D6\n",
      "7    A7   B7   C7   D7\n",
      "8    A8   B8   C8   D8\n",
      "9    A9   B9   C9   D9\n",
      "10  A10  B10  C10  D10\n",
      "11  A11  B11  C11  D11\n",
      "\n",
      "\n",
      "Concatenating on columns - \n",
      "\n",
      "       A    B    C    D    A    B    C    D    A    B    C    D\n",
      "0    A0   B0   C0   D0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "1    A1   B1   C1   D1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "2    A2   B2   C2   D2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "3    A3   B3   C3   D3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "4   NaN  NaN  NaN  NaN   A4   B4   C4   D4  NaN  NaN  NaN  NaN\n",
      "5   NaN  NaN  NaN  NaN   A5   B5   C5   D5  NaN  NaN  NaN  NaN\n",
      "6   NaN  NaN  NaN  NaN   A6   B6   C6   D6  NaN  NaN  NaN  NaN\n",
      "7   NaN  NaN  NaN  NaN   A7   B7   C7   D7  NaN  NaN  NaN  NaN\n",
      "8   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   A8   B8   C8   D8\n",
      "9   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   A9   B9   C9   D9\n",
      "10  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  A10  B10  C10  D10\n",
      "11  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  A11  B11  C11  D11\n",
      "\n",
      "\n",
      "New dataframe (left) - \n",
      "\n",
      "   key   A   B\n",
      "0  K0  A0  B0\n",
      "1  K1  A1  B1\n",
      "2  K2  A2  B2\n",
      "3  K3  A3  B3\n",
      "\n",
      "\n",
      "New dataframe (right) - \n",
      "\n",
      "   key   C   D\n",
      "0  K0  C0  D0\n",
      "1  K1  C1  D1\n",
      "2  K2  C2  D2\n",
      "3  K3  C3  D3\n",
      "\n",
      "\n",
      "Merging left and right dataframes on column key - \n",
      "\n",
      "   key   A   B   C   D\n",
      "0  K0  A0  B0  C0  D0\n",
      "1  K1  A1  B1  C1  D1\n",
      "2  K2  A2  B2  C2  D2\n",
      "3  K3  A3  B3  C3  D3\n",
      "\n",
      "\n",
      "New complex dataframe (left) - \n",
      "\n",
      "   key1 key2   A   B\n",
      "0   K0   K0  A0  B0\n",
      "1   K0   K1  A1  B1\n",
      "2   K1   K0  A2  B2\n",
      "3   K2   K1  A3  B3\n",
      "\n",
      "\n",
      "New complex dataframe (right) - \n",
      "\n",
      "   key1 key2   C   D\n",
      "0   K0   K0  C0  D0\n",
      "1   K1   K0  C1  D1\n",
      "2   K1   K0  C2  D2\n",
      "3   K2   K0  C3  D3\n",
      "\n",
      "\n",
      "Complex dataframes merge based on multiple keys - \n",
      "\n",
      "   key1 key2   A   B   C   D\n",
      "0   K0   K0  A0  B0  C0  D0\n",
      "1   K1   K0  A2  B2  C1  D1\n",
      "2   K1   K0  A2  B2  C2  D2\n",
      "\n",
      "\n",
      "New dataframe for joining (leftJoin) - \n",
      "\n",
      "      A   B\n",
      "K0  A0  B0\n",
      "K1  A1  B1\n",
      "K2  A2  B2\n",
      "\n",
      "\n",
      "New dataframe for joining (rightJoin) - \n",
      "\n",
      "      C   D\n",
      "K0  C0  D0\n",
      "K2  C2  D2\n",
      "K3  C3  D3\n",
      "\n",
      "\n",
      "leftJoin.join(rightJoin) - \n",
      "\n",
      "      A   B    C    D\n",
      "K0  A0  B0   C0   D0\n",
      "K1  A1  B1  NaN  NaN\n",
      "K2  A2  B2   C2   D2\n",
      "\n",
      "\n",
      "leftJoin.join(rightJoin, how='outer) - \n",
      "\n",
      "       A    B    C    D\n",
      "K0   A0   B0   C0   D0\n",
      "K1   A1   B1  NaN  NaN\n",
      "K2   A2   B2   C2   D2\n",
      "K3  NaN  NaN   C3   D3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                        'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                        'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                        'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                        index=[0, 1, 2, 3])\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                        'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                        'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                        'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                         index=[4, 5, 6, 7]) \n",
    "\n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                        'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                        'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "                        'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "                        index=[8, 9, 10, 11])\n",
    "\n",
    "print(\"\\n\\nDataframe1 - \\n\\n\", df1)\n",
    "print(\"\\n\\nDataframe2 - \\n\\n\", df2)\n",
    "print(\"\\n\\nDataframe3 - \\n\\n\", df3)\n",
    "\n",
    "# concatenation of dataframes\n",
    "# it basically glues together dataframes\n",
    "# the dimensions should match along the axis on which we are concatenating otherwise we land up with NaN values\n",
    "# we can use pd.concat and pass in a list of dataframes to concatenate together\n",
    "print(\"\\n\\nConcatenating on rows - \\n\\n\", pd.concat([df1, df2, df3]))\n",
    "print(\"\\n\\nConcatenating on columns - \\n\\n\", pd.concat([df1, df2, df3], axis=1))\n",
    "\n",
    "left = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "   \n",
    "right = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                          'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                          'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "print(\"\\n\\nNew dataframe (left) - \\n\\n\", left)\n",
    "print(\"\\n\\nNew dataframe (right) - \\n\\n\", right)\n",
    "\n",
    "# merging of dataframes\n",
    "# the merge function allows us to merge dataframes together using a similar logic as MySQL\n",
    "print(\"\\n\\nMerging left and right dataframes on column key - \\n\\n\", pd.merge(left, right, how='inner', on='key'))\n",
    "\n",
    "leftComplex= pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                        'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                        'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "    \n",
    "rightComplex = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                               'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                                  'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                                  'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "print(\"\\n\\nNew complex dataframe (left) - \\n\\n\", leftComplex)\n",
    "print(\"\\n\\nNew complex dataframe (right) - \\n\\n\", rightComplex)\n",
    "\n",
    "print(\"\\n\\nComplex dataframes merge based on multiple keys - \\n\\n\", pd.merge(leftComplex, rightComplex, on=['key1', 'key2']))\n",
    "\n",
    "leftJoin = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
    "                     'B': ['B0', 'B1', 'B2']},\n",
    "                      index=['K0', 'K1', 'K2']) \n",
    "\n",
    "rightJoin = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D2', 'D3']},\n",
    "                      index=['K0', 'K2', 'K3'])\n",
    "\n",
    "print(\"\\n\\nNew dataframe for joining (leftJoin) - \\n\\n\", leftJoin)\n",
    "print(\"\\n\\nNew dataframe for joining (rightJoin) - \\n\\n\", rightJoin)\n",
    "\n",
    "# joining of dataframes\n",
    "# joining is a convenient method for combining the columns of two potentially differently-indexed dataframes into a single result dataframe\n",
    "print(\"\\n\\nleftJoin.join(rightJoin) - \\n\\n\", leftJoin.join(rightJoin))\n",
    "print(\"\\n\\nleftJoin.join(rightJoin, how='outer) - \\n\\n\", leftJoin.join(rightJoin, how='outer'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
